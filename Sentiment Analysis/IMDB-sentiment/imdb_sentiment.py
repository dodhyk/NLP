# -*- coding: utf-8 -*-
"""IMDB sentiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UO3FgwBOF9wnUrWdGGURe74CRX5Yij07
"""

# Import Library yang dibutuhkan
import pandas as pd
import numpy as np
import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
nltk.download('wordnet')
nltk.download('stopwords')

# Menghapus tanda baca
def del_punctuation(message):
  punc_remover = [text for text in message if text not in string.punctuation]
  punc_remover_join = ''.join(punc_remover)
  return punc_remover_join

# Menghapus kata yang tidak bermakna
def del_stopwords(message):
  stopwords_remover = [text for text in message.split() if text not in stopwords.words('english')]
  stopwords_remover_join = ' '.join(stopwords_remover)
  
  return stopwords_remover_join

# Mengubah suatu kata ke bentuk dasar
def change_stem(message):
  lemmatizer = WordNetLemmatizer()
  lemma_changer = [lemmatizer.lemmatize(text) for text in message.split()]
  lemma = ' '.join(lemma_changer)
  
  return lemma

# Import dataset
data = pd.read_csv('imdb_dataset.csv')

# Tahap Preprocessing
def preprocessing(x):
  x = x.copy()

  # Lower the text
  x['review'] = x['review'].str.lower()

  # delete html tags
  x['review'] = x['review'].str.replace('<[^>]+>', '')

  # delete punctuation
  x['review'] = x['review'].apply(del_punctuation)

  # delete stopwords
  x['review'] = x['review'].apply(del_stopwords)

  # doing stemming
  x['review'] = x['review'].apply(change_stem)

  return x

# Masukkan data ke preprocessing
df = preprocessing(data)
df

# Membagi data menjadi data latih dan data uji
from sklearn.model_selection import train_test_split

X = df.drop('sentiment', axis=1)
y = df['sentiment']

X_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state=1)

# Memberikan bobot kata menggunakan TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
hasil_vector = vectorizer.fit_transform(X_train['review']).toarray()

X_train = hasil_vector
x_test = vectorizer.transform(x_test['review']).toarray()

# Melakukan modelling metode machine learning
from sklearn.linear_model import LogisticRegression

modelLr = LogisticRegression()
modelLr.fit(X_train, y_train)

# Melakukan predict dengan model yang telah dibuat
y_predict = modelLr.predict(x_test)

# Melihat tingkat akurasi model
from sklearn.metrics import accuracy_score, confusion_matrix
accuracy_score(y_test, y_predict)

# Mencari presisi dan recall dengan menggunakan confusion matrix
confusion_matrix(y_test, y_predict)

TP = 98
TN = 100
FP = 41
FN = 11

precision = TP/(TP+FP)
recall = TP/(TP+FN)

print("Precision : " + str(precision))
print("Recall : " + str(recall))

